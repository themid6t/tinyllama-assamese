{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11149509,"sourceType":"datasetVersion","datasetId":6955946},{"sourceId":11448073,"sourceType":"datasetVersion","datasetId":6973808}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning TinyLlama/TinyLlama-1.1B-Chat-v1.0 for fluency in Assamese.\n## Training in two stages.\n\n### Stage 1: Domain-adaptive pretraining\nTraining the model on raw Assamese text data, exposing the model to the language's vocabulary, grammar, and cultural context, improving it generation quality in Assamese.  \n### Stage 2: Tast-specific fine-tuning\nFine-tuning on conversation dataset, adaots the model to dialogue patterns, ensuring it responds appropriately in Assamese conversations.  \n\n**This approach mitigates TinyLlama's limited pretraining exposure to Assamese, reducing issues like poor tokenization or unnatural responses.**","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastLanguageModel, UnslothTrainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T06:37:41.619010Z","iopub.execute_input":"2025-04-18T06:37:41.619718Z","iopub.status.idle":"2025-04-18T06:37:54.846661Z","shell.execute_reply.started":"2025-04-18T06:37:41.619685Z","shell.execute_reply":"2025-04-18T06:37:54.845828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import TrainingArguments\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T06:37:54.847827Z","iopub.execute_input":"2025-04-18T06:37:54.848088Z","iopub.status.idle":"2025-04-18T06:37:54.852231Z","shell.execute_reply.started":"2025-04-18T06:37:54.848058Z","shell.execute_reply":"2025-04-18T06:37:54.851497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T06:38:19.108847Z","iopub.execute_input":"2025-04-18T06:38:19.109440Z","iopub.status.idle":"2025-04-18T06:38:19.124018Z","shell.execute_reply.started":"2025-04-18T06:38:19.109411Z","shell.execute_reply":"2025-04-18T06:38:19.123199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We are training with a context window of only 1024 due to limited hardware.\nMAX_SEQ_LENGTH = 1024","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T06:39:08.150441Z","iopub.execute_input":"2025-04-18T06:39:08.151106Z","iopub.status.idle":"2025-04-18T06:39:08.155036Z","shell.execute_reply.started":"2025-04-18T06:39:08.151068Z","shell.execute_reply":"2025-04-18T06:39:08.154273Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Loading the model in 4-bit quantized format for efficiency and applying lora adapters.","metadata":{}},{"cell_type":"code","source":"# Load the model and tokenizer\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n    max_seq_length=MAX_SEQ_LENGTH, \n    dtype=torch.float16,     # Mixed Precision\n    load_in_4bit=True,        # 4-bit quantization\n    # device_map=\"auto\",\n)\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    use_gradient_checkpointing=True,\n    random_state=1337,\n)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T06:39:17.657771Z","iopub.execute_input":"2025-04-18T06:39:17.658606Z","iopub.status.idle":"2025-04-18T06:39:25.534156Z","shell.execute_reply.started":"2025-04-18T06:39:17.658565Z","shell.execute_reply":"2025-04-18T06:39:25.533511Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load dataset for both the stages.\n### raw_dataset - contains 12k high quality Assamese sentences\n### conv_dataset - contains 2k samples of user->assistant conversation","metadata":{}},{"cell_type":"code","source":"# Stage 1 & 2 datasets\nraw_dataset = load_dataset(\"text\", data_files=\"/kaggle/input/train-as/train-01.txt\", split=\"train\")\nconv_dataset = load_dataset(\"json\", data_files=\"/kaggle/input/as-train-processed/conversations.jsonl\", split=\"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T06:39:25.535166Z","iopub.execute_input":"2025-04-18T06:39:25.535437Z","iopub.status.idle":"2025-04-18T06:39:25.857959Z","shell.execute_reply.started":"2025-04-18T06:39:25.535416Z","shell.execute_reply":"2025-04-18T06:39:25.857139Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Stage 1 setup and training.","metadata":{}},{"cell_type":"code","source":"training_args_stage1=TrainingArguments(\n    output_dir=\"/kaggle/working/as/tinyllama-training-stage1\",\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    max_steps=1600,\n    learning_rate=1e-4,  # Smaller learning rate for stage 1\n    fp16=not torch.cuda.is_bf16_supported(),  # Use FP16 if BF16 is not supported\n    bf16=torch.cuda.is_bf16_supported(),  # Use BF16 if supported\n    save_steps=200,\n    logging_dir=\"/kaggle/working/as/logs_stage1\",\n    logging_steps=100,\n    optim=\"adamw_8bit\",  # Memory-efficient optimizer\n    report_to=\"none\",\n    warmup_steps=100,\n\n    dataloader_num_workers=4,    # Added for faster data loading\n    dataloader_pin_memory=True,  # Added for efficient GPU transfer\n    \n    seed=1337,\n)\n\ntrainer_stage1 = SFTTrainer(\n    model=model,\n    train_dataset=raw_dataset,   # using the raw_text dataset\n    tokenizer=tokenizer,\n    dataset_text_field=\"text\",  # Field name in the dataset containing text\n    max_seq_length=MAX_SEQ_LENGTH,\n    dataset_num_proc=2,  # Number of processes for data preprocessing\n    args=training_args_stage1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T06:39:37.000798Z","iopub.execute_input":"2025-04-18T06:39:37.001399Z","iopub.status.idle":"2025-04-18T06:39:37.205897Z","shell.execute_reply.started":"2025-04-18T06:39:37.001372Z","shell.execute_reply":"2025-04-18T06:39:37.205385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer_stage1.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T06:39:41.042528Z","iopub.execute_input":"2025-04-18T06:39:41.042825Z","iopub.status.idle":"2025-04-18T15:27:16.735940Z","shell.execute_reply.started":"2025-04-18T06:39:41.042802Z","shell.execute_reply":"2025-04-18T15:27:16.735192Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Save domain adaptive model to local dir and hf","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/as/trained-stage1/tinyllama-lora-adapters\")\ntokenizer.save_pretrained(\"/kaggle/working/as/trained-stage1/tinyllama-lora-adapters\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:27:16.737430Z","iopub.execute_input":"2025-04-18T15:27:16.737686Z","iopub.status.idle":"2025-04-18T15:27:17.119112Z","shell.execute_reply.started":"2025-04-18T15:27:16.737662Z","shell.execute_reply":"2025-04-18T15:27:17.118503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.push_to_hub(\"themid6t/assamese-tinyllama-base\")\ntokenizer.push_to_hub(\"themid6t/assamese-tinyllama-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:27:17.119690Z","iopub.execute_input":"2025-04-18T15:27:17.119901Z","iopub.status.idle":"2025-04-18T15:27:50.164613Z","shell.execute_reply.started":"2025-04-18T15:27:17.119883Z","shell.execute_reply":"2025-04-18T15:27:50.163859Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Stage 2 setup and training","metadata":{}},{"cell_type":"code","source":"def format_conversations(examples):\n    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant fluent in Assamese.\"}] + examples[\"messages\"]\n    formatted_text = tokenizer.apply_chat_template(messages, tokenize=False)\n    return {\"text\": formatted_text}\n\nconv_dataset = conv_dataset.map(format_conversations, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:27:50.166122Z","iopub.execute_input":"2025-04-18T15:27:50.166391Z","iopub.status.idle":"2025-04-18T15:27:50.311860Z","shell.execute_reply.started":"2025-04-18T15:27:50.166366Z","shell.execute_reply":"2025-04-18T15:27:50.311015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conv_dataset[0][\"text\"][:1000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:27:50.312653Z","iopub.execute_input":"2025-04-18T15:27:50.312868Z","iopub.status.idle":"2025-04-18T15:27:50.318541Z","shell.execute_reply.started":"2025-04-18T15:27:50.312850Z","shell.execute_reply":"2025-04-18T15:27:50.317844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configure training for supervised fine-tuning\ntraining_args_stage2 = TrainingArguments(\n    output_dir=\"./fine_tuned_tinyllama\",\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    learning_rate=2e-4,\n    num_train_epochs=10,\n    # max_steps=500,  # Adjust based on dataset size\n    # logging_steps=10,\n    save_steps=100,\n    fp16=not torch.cuda.is_bf16_supported(),  # Use FP16 if BF16 is not supported\n    bf16=torch.cuda.is_bf16_supported(),  # Use BF16 if supported\n    optim=\"adamw_8bit\",\n    report_to=\"none\",\n    # warmup_steps=50\n)\n\ntrainer_stage2 = SFTTrainer(\n    model=model,  # Reuse the same model instance\n    tokenizer=tokenizer,\n    train_dataset=conv_dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=MAX_SEQ_LENGTH,\n    args=training_args_stage2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:27:50.319325Z","iopub.execute_input":"2025-04-18T15:27:50.319632Z","iopub.status.idle":"2025-04-18T15:27:51.913903Z","shell.execute_reply.started":"2025-04-18T15:27:50.319614Z","shell.execute_reply":"2025-04-18T15:27:51.913277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer_stage2.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:27:51.914853Z","iopub.execute_input":"2025-04-18T15:27:51.915130Z","iopub.status.idle":"2025-04-18T15:39:18.939656Z","shell.execute_reply.started":"2025-04-18T15:27:51.915106Z","shell.execute_reply":"2025-04-18T15:39:18.939079Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Save the conversation model to hf and local dir","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/as/trained-stage2/tinyllama-lora-adapters\")\ntokenizer.save_pretrained(\"/kaggle/working/as/trained-stage2/tinyllama-lora-adapters\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:39:18.940398Z","iopub.execute_input":"2025-04-18T15:39:18.940615Z","iopub.status.idle":"2025-04-18T15:39:19.350802Z","shell.execute_reply.started":"2025-04-18T15:39:18.940598Z","shell.execute_reply":"2025-04-18T15:39:19.350010Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.push_to_hub(\"themid6t/assamese-tinyllama-chat\")\ntokenizer.push_to_hub(\"themid6t/assamese-tinyllama-chat\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:39:19.351714Z","iopub.execute_input":"2025-04-18T15:39:19.351992Z","iopub.status.idle":"2025-04-18T15:39:26.144963Z","shell.execute_reply.started":"2025-04-18T15:39:19.351967Z","shell.execute_reply":"2025-04-18T15:39:26.144192Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Infer and test","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:39:26.147044Z","iopub.execute_input":"2025-04-18T15:39:26.147269Z","iopub.status.idle":"2025-04-18T15:39:26.280271Z","shell.execute_reply.started":"2025-04-18T15:39:26.147250Z","shell.execute_reply":"2025-04-18T15:39:26.279531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:39:26.281024Z","iopub.execute_input":"2025-04-18T15:39:26.281230Z","iopub.status.idle":"2025-04-18T15:39:26.287426Z","shell.execute_reply.started":"2025-04-18T15:39:26.281212Z","shell.execute_reply":"2025-04-18T15:39:26.286731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"messages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant fluent in Assamese.\"},\n    {\"role\": \"user\", \"content\": \"আপুনি কোন?\"}\n]\nprompt = tokenizer.apply_chat_template(messages, tokenize=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:06:53.125967Z","iopub.execute_input":"2025-04-18T16:06:53.126221Z","iopub.status.idle":"2025-04-18T16:06:53.129975Z","shell.execute_reply.started":"2025-04-18T16:06:53.126203Z","shell.execute_reply":"2025-04-18T16:06:53.129399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7)\nprint(outputs[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:07:16.398399Z","iopub.execute_input":"2025-04-18T16:07:16.399200Z","iopub.status.idle":"2025-04-18T16:07:17.399802Z","shell.execute_reply.started":"2025-04-18T16:07:16.399168Z","shell.execute_reply":"2025-04-18T16:07:17.399030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a ZIP archive\n!zip -r /kaggle/working/as.zip /kaggle/working/as\n\n# Download directly from notebook\nfrom IPython.display import FileLink\nFileLink(r'/kaggle/working/as.zip')  # Click this link","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:56:00.792688Z","iopub.execute_input":"2025-04-18T15:56:00.792967Z","iopub.status.idle":"2025-04-18T15:56:37.309094Z","shell.execute_reply.started":"2025-04-18T15:56:00.792940Z","shell.execute_reply":"2025-04-18T15:56:37.308375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}